{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Record Merging\n",
    "This *.ipynb file is used to merge records of the original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing packages\n",
    "import ast\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# a helper function\n",
    "def output(outname,df):\n",
    "    outdir = './'\n",
    "    if not os.path.exists(outdir):\n",
    "        os.mkdir(outdir)\n",
    "\n",
    "    fullname = os.path.join(outdir, outname)    \n",
    "    df.to_csv(fullname)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we normalized the data by replacing the inconsistent Missing value representation of the data, for consistency, we changed them all into Missing. Then, we saved them as \"1_Normalized_data.csv\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Cleaned_data_v8.csv')\n",
    "data.fillna(\"Missing\",inplace = True)\n",
    "data.replace(\"MISS\",\"Missing\",inplace= True)\n",
    "data.replace(\" MISS\",\"Missing\",inplace= True)\n",
    "data.replace(\"--\",\"Missing\",inplace= True)\n",
    "output(\"1_Normalized_data.csv\",data)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second, we filter out the records which have the same value in \"SOURCE: Folder No MOD\",\"APPLICATION: Year filed MOD\",\"APPLICATION: Month MOD\", and \"APPLICATION: Day MOD\" with another record, which means that these records have duplicates(i.e. filled out multiple time by Lab RAs). We stored the records we found in the file \"3_Duplicated.csv\".\n",
    "\n",
    "We also filter out the records that do not have the same value as other records in \"SOURCE: Folder No MOD\",\"APPLICATION: Year filed MOD\",\"APPLICATION: Month MOD\", \"APPLICATION: Day MOD\", which means that these records have no duplicates(i.e. filled out only one time by Lab RAs), We stored the records we found in the file \"2_UnDuplicated.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('1_Normalized_data.csv')\n",
    "#find dupicate by file and output\n",
    "df1=data.groupby([\"SOURCE: Folder No MOD\",\"APPLICATION: Year filed MOD\",\"APPLICATION: Month MOD\",\n",
    "\"APPLICATION: Day MOD\"]).size()\n",
    "col=df1[df1==1].reset_index()[[\"SOURCE: Folder No MOD\",\"APPLICATION: Year filed MOD\",\"APPLICATION: Month MOD\",\n",
    "\"APPLICATION: Day MOD\"]]\n",
    "a = pd.merge(col,data,on=[\"SOURCE: Folder No MOD\",\"APPLICATION: Year filed MOD\",\"APPLICATION: Month MOD\",\n",
    "\"APPLICATION: Day MOD\"])\n",
    "a.drop(columns='Unnamed: 0',inplace=True)\n",
    "output(\"2_UnDuplicated.csv\",a)\n",
    "\n",
    "data = pd.read_csv('1_Normalized_data.csv')\n",
    "#find dupicate by file and output\n",
    "df1=data.groupby([\"SOURCE: Folder No MOD\",\"APPLICATION: Year filed MOD\",\"APPLICATION: Month MOD\",\n",
    "\"APPLICATION: Day MOD\"]).size()\n",
    "col=df1[df1>1].reset_index()[[\"SOURCE: Folder No MOD\",\"APPLICATION: Year filed MOD\",\"APPLICATION: Month MOD\",\n",
    "\"APPLICATION: Day MOD\"]]\n",
    "b = pd.merge(col,data,on=[\"SOURCE: Folder No MOD\",\"APPLICATION: Year filed MOD\",\"APPLICATION: Month MOD\",\n",
    "\"APPLICATION: Day MOD\"])\n",
    "b.drop(columns='Unnamed: 0',inplace=True)\n",
    "print(b)\n",
    "output(\"3_Duplicated.csv\",b)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Third, we merge the duplicated records in the file \"3_Duplicated.csv\".\n",
    "\n",
    "\n",
    "We group the duplicated records when they have had the same value in \"SOURCE: Folder No MOD\",\"APPLICATION: Year filed MOD\",\"APPLICATION: Month MOD\", and \"APPLICATION: Day MOD\". When we grouped the duplicated records into one record, only the unique answers in each field is saved(the order of the answer is consistent with the index of the record, the smaller the index is, the answer will be present in front). For example. Duplicate A,B,C has the same value in \"SOURCE: Folder No MOD\",\"APPLICATION: Year filed MOD\",\"APPLICATION: Month MOD\", and \"APPLICATION: Day MOD\". Duplicate A have value of 1 in the field ExampleField, Duplicate B has value of 1 in the field ExampleField, Duplicate C has value of 2 in the field ExampleField. The final merged record will have value 1,2 in the field ExampleField. The merged record is saved in \"5_Clean_Merge_Dupicated.csv\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = pd.read_csv('3_Duplicated.csv')\n",
    "#merge data\n",
    "df1 = data.astype(str).groupby([\"SOURCE: Folder No MOD\",\"APPLICATION: Year filed MOD\",\"APPLICATION: Month MOD\",\"APPLICATION: Day MOD\"], as_index=False).agg(list)\n",
    "df = df1.drop(columns=['Unnamed: 0'])\n",
    "output(\"4_Merge_Duplicated.csv\",df)\n",
    "\n",
    "\n",
    "data = pd.read_csv('4_Merge_Duplicated.csv',dtype=str)\n",
    "#clean merge data\n",
    "def fx(i):\n",
    "    if type(i) is str and '[' in i:\n",
    "        x = ast.literal_eval(i)\n",
    "        x = [n.strip() for n in x]\n",
    "        print(type(x))\n",
    "        result = list(dict.fromkeys(x))\n",
    "        while result.count(\"Missing\") >= 1 and len(result) >1:\n",
    "            result.remove(\"Missing\")\n",
    "        fr = ','.join(result)\n",
    "        return fr\n",
    "    else:\n",
    "        return i\n",
    "mydata = data.applymap(fx)\n",
    "df = mydata.drop(columns=['Unnamed: 0'])\n",
    "output(\"5_Clean_Merge_Dupicated.csv\",df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Forth, we combined the \"5_Clean_Merge_Dupicated.csv\" file and \"2_UnDuplicated.csv\" file into a single file and then we reorganized the field, moving some important fields ('SOURCE: Folder Number','SOURCE: Folder No MOD',\"APPLICATION: Year filed\",\"APPLICATION: Year filed MOD\", etc) in the front for better view. We stored it in the file \"7_Cleaned_data_v9.csv\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#combina two data set\n",
    "data1 = pd.read_csv('5_Clean_Merge_Dupicated.csv')\n",
    "data2 = pd.read_csv('2_UnDuplicated.csv')\n",
    "frames = [data1,data2]\n",
    "result = pd.concat(frames)\n",
    "df = result.drop(columns=['Unnamed: 0'])\n",
    "df_id = df[\"APPLICATION: Year filed\"]\n",
    "df = df.drop('APPLICATION: Year filed',axis=1)\n",
    "df.insert(1,'APPLICATION: Year filed',df_id)\n",
    "output(\"6_Cleaned_data_v9.csv\",df)\n",
    "\n",
    "# #reorganized data\n",
    "data = pd.read_csv('6_Cleaned_data_v9.csv')\n",
    "df = data.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "df_id = df[\"SOURCE: Folder Number\"]\n",
    "df = df.drop('SOURCE: Folder Number',axis=1)\n",
    "df.insert(0,'SOURCE: Folder Number',df_id)\n",
    "\n",
    "df_id = df[\"SOURCE: Folder No MOD\"]\n",
    "df = df.drop('SOURCE: Folder No MOD',axis=1)\n",
    "df.insert(1,'SOURCE: Folder No MOD',df_id)\n",
    "\n",
    "df_id = df[\"APPLICATION: Year filed\"]\n",
    "df = df.drop('APPLICATION: Year filed',axis=1)\n",
    "df.insert(2,'APPLICATION: Year filed',df_id)\n",
    "\n",
    "df_id = df[\"APPLICATION: Year filed MOD\"]\n",
    "df = df.drop('APPLICATION: Year filed MOD',axis=1)\n",
    "df.insert(3,'APPLICATION: Year filed MOD',df_id)\n",
    "\n",
    "df_id = df[\"APPLICATION: Month filed\"]\n",
    "df = df.drop('APPLICATION: Month filed',axis=1)\n",
    "df.insert(4,'APPLICATION: Month filed',df_id)\n",
    "\n",
    "df_id = df[\"APPLICATION: Month MOD\"]\n",
    "df = df.drop('APPLICATION: Month MOD',axis=1)\n",
    "df.insert(5,'APPLICATION: Month MOD',df_id)\n",
    "\n",
    "df_id = df[\"APPLICATION: Day filed\"]\n",
    "df = df.drop('APPLICATION: Day filed',axis=1)\n",
    "df.insert(6,'APPLICATION: Day filed',df_id)\n",
    "\n",
    "df_id = df[\"APPLICATION: Day MOD\"]\n",
    "df = df.drop('APPLICATION: Day MOD',axis=1)\n",
    "df.insert(7,'APPLICATION: Day MOD',df_id)\n",
    "\n",
    "df_id = df[\"#ID\"]\n",
    "df = df.drop('#ID',axis=1)\n",
    "df.insert(0,'#ID',df_id)\n",
    "# df['#ID'] = range(1, len(df) + 1)\n",
    "# df_id = df[\"#ID\"]\n",
    "# df = df.drop('#ID',axis=1)\n",
    "# df.insert(0,'#ID',df_id)\n",
    "\n",
    "\n",
    "output(\"7_Cleaned_data_v9.csv\",df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we categorized the data into 3 types\n",
    "- Family data\n",
    "- Single data W/ multiple input\n",
    "- Single data W/ 1 input\n",
    "\n",
    "\n",
    "If the record has child/wife/Daugther in its field 'APPLICATION: Type', we marked the record as family data. Meaning that this record has merged the information of a family (Why? because family member have the same file name and application date, which meet the merging criteria we mentioned above)\n",
    "\n",
    "\n",
    "If the record has no child/wife/Daugther in its field 'APPLICATION: Type', and it is a merged record, we marked the record as Single data W/ multiple input.\n",
    "\n",
    "\n",
    "If the record has no child/wife/Daugther in its field 'APPLICATION: Type', and it is a not merged record, we marked the record as Single data W/ 1 input.\n",
    "\n",
    "\n",
    "This information is stored in the field \"DATA TYPE\".\n",
    "\n",
    "\n",
    "After we create the field \"DATA TYPE\" for every record, we give them a unique ID that is the mixture of ascii_uppercase char and number digits of length 6.\n",
    "\n",
    "\n",
    "We stored the file in \"DATA.csv\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Get coloums that contain family info, mulitpule SOURCE: Name on File or APPLICATION: Type MOD DETAILED\n",
    "data = pd.read_csv('7_Cleaned_data_v9.csv')\n",
    "\n",
    "\n",
    "family_data = data[data['APPLICATION: Type'].str.contains(',')]\n",
    "family_data_Child = family_data[family_data['APPLICATION: Type'].str.contains('Child')]\n",
    "\n",
    "family_data_Wife = family_data[family_data['APPLICATION: Type'].str.contains('Wife')]\n",
    "\n",
    "family_data_child = family_data[family_data['APPLICATION: Type'].str.contains('child')]\n",
    "\n",
    "family_data_wife = family_data[family_data['APPLICATION: Type'].str.contains('wife')]\n",
    "\n",
    "family_data_d = family_data[family_data['APPLICATION: Type'].str.contains('Daugther')]\n",
    "\n",
    "\n",
    "family_data1 = pd.concat([family_data_Child,family_data_Wife, family_data_child,family_data_wife,family_data_d]).drop_duplicates(keep= \"first\")\n",
    "\n",
    "not_family_data = pd.concat([data, family_data1, family_data1]).drop_duplicates(keep=False)\n",
    "\n",
    "multi_data1 = not_family_data[not_family_data['Timestamp'].str.contains(',')]\n",
    "\n",
    "left_over = pd.concat([not_family_data, multi_data1, multi_data1]).drop_duplicates(keep=False)\n",
    "print(len(data))\n",
    "print(len(family_data1))\n",
    "print(len(multi_data1))\n",
    "print(len(left_over))\n",
    "\n",
    "family_data1.drop(columns='Unnamed: 0',inplace=True)\n",
    "multi_data1.drop(columns='Unnamed: 0',inplace=True)\n",
    "left_over.drop(columns='Unnamed: 0',inplace=True)\n",
    "\n",
    "\n",
    "#add type\n",
    "family_data1['DATA TYPE'] = [\"Family data\"]*len(family_data1)\n",
    "df_id = family_data1[\"DATA TYPE\"]\n",
    "family_data1 = family_data1.drop('DATA TYPE',axis=1)\n",
    "family_data1.insert(0,'DATA TYPE',df_id)\n",
    "\n",
    "multi_data1['DATA TYPE'] = [\"Single data W/ multiple input\"]*len(multi_data1)\n",
    "df_id = multi_data1[\"DATA TYPE\"]\n",
    "multi_data1 = multi_data1.drop('DATA TYPE',axis=1)\n",
    "multi_data1.insert(0,'DATA TYPE',df_id)\n",
    "\n",
    "left_over['DATA TYPE'] = [\"Single data W/ 1 input\"]*len(left_over)\n",
    "df_id = left_over[\"DATA TYPE\"]\n",
    "left_over = left_over.drop('DATA TYPE',axis=1)\n",
    "left_over.insert(0,'DATA TYPE',df_id)\n",
    "\n",
    "\n",
    "#combine\n",
    "wholedata = pd.concat([family_data1,multi_data1, left_over])\n",
    "\n",
    "#add unique id\n",
    "import random\n",
    "import string\n",
    "import numpy as np\n",
    "def id_generator(size=6, chars=string.ascii_uppercase + string.digits):\n",
    "    return ''.join(random.SystemRandom().choice(chars) for _ in range(size))\n",
    "\n",
    "wholedata['ID'] = wholedata['#ID'].apply(lambda x : id_generator(5))\n",
    "\n",
    "df_id = wholedata[\"ID\"]\n",
    "wholedata = wholedata.drop('ID',axis=1)\n",
    "wholedata.insert(0,'ID',df_id)\n",
    "\n",
    "\n",
    "\n",
    "wholedata.reset_index(inplace=True,drop = True)\n",
    "\n",
    "\n",
    "wholedata.replace('Missing', np.NaN,inplace= True)\n",
    "\n",
    "output(\"DATA.csv\",wholedata)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.16 (default, Jan 17 2023, 16:42:09) \n[Clang 14.0.6 ]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "54433340cf721f9bc16a25cecc872cc5f7f905161b5133563a0c77619458de86"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
