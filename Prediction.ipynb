{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction Code\n",
    "\n",
    "This file demonstrate the code we used to predict the missing values in our dataset."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We used a machine learning technique (Xgb regressor) to fill in missing values from the restaurant section. There are 13 columns in the restaurant section, with 504 data records, which are extracted from our cleaned database with [COL N] and 504 records. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore')\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn.base import BaseEstimator\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data set of the first layer of predictions was the data from ID, REST, and three related fields from the LRC section [WHY LRC? ](i.e. 17 columns in total, 1 ID column, 13 columns from the restaurant section, and 3 related columns from the LRC section). We marked this section of data as REST1 for the rest of the article.  After we spilt the REST1 into the training data set and the testing data set, we trained our XgbRegressor model with the training data set and tuned the parameters of the XgbRegressor using grid search and cross-validation method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SplitSet(target: str, filename: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Input: the target column name, the name of the original dataset\n",
    "    Output: x, y, xtrain, xtest, ytrain, ytest\n",
    "    This function split the original file into train and test set.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(filename)\n",
    "    df = df.drop(['ID'],axis = 1)\n",
    "    df = df.dropna(axis=0, how='all')\n",
    "    df = df.dropna(axis=0,subset = [target])\n",
    "    y = df[target]\n",
    "    x = df.drop([target],axis = 1)\n",
    "    xtrain, xtest, ytrain, ytest=train_test_split(x, y, test_size=0.15,random_state =10)\n",
    "    return x, y, xtrain, xtest, ytrain, ytest\n",
    "\n",
    "def XgbModel(xtrain: pd.DataFrame, ytrain: pd.DataFrame,x: pd.DataFrame,y: pd.DataFrame) -> BaseEstimator:\n",
    "    \"\"\"\n",
    "    Input: the trainset for x, the training set for y, x, and y\n",
    "    Output: the model\n",
    "    This function gives the best xgbmodel using gridserch and cross validation and then return it.\n",
    "    \"\"\"\n",
    "    params = {\n",
    "    'learning_rate': [0.1, 0.01, 0.05],\n",
    "    'n_estimators': [100,600,1000],\n",
    "    'max_depth': [1,3],\n",
    "    'lambda':[0,0.5,1],\n",
    "    'alpha':[0,0.5,1]\n",
    "    }\n",
    "\n",
    "    xgbr = xgb.XGBRegressor(seed = 20)\n",
    "    clf = GridSearchCV(estimator=xgbr, \n",
    "                    param_grid=params,\n",
    "                    scoring='neg_mean_absolute_percentage_error', \n",
    "                    verbose=1,\n",
    "                    cv=2,\n",
    "                    )\n",
    "    clf.fit(xtrain, ytrain)\n",
    "    print(\"Best parameters:\", clf.best_params_)\n",
    "    print(\"Best scores:\", clf.best_score_)\n",
    "\n",
    "    xgb_model = clf.best_estimator_\n",
    "    scores = cross_val_score(xgbr, x, y, cv=5, scoring='neg_mean_absolute_percentage_error')\n",
    "    scores =  np.absolute(scores)\n",
    "    print('MAPE CV Score: %.3f (%.3f)' % (scores.mean(), scores.std()) )\n",
    "    \n",
    "    return xgb_model\n",
    "\n",
    "\n",
    "\n",
    "def Predict(previous_file: str, target: str, xgbr: BaseEstimator , new_file_name : str , p_v: str) -> None:\n",
    "    \"\"\"\n",
    "    Input: the previous_file name , the name of the target column, the xgb model, the name of the new file, the addition string\n",
    "    Output: None\n",
    "    This function add the prediction of a traget column to previous file and then save it in a new file.\n",
    "    \"\"\"\n",
    "    previous_df = pd.read_csv(previous_file)\n",
    "    orginal_df = pd.read_csv('./data/REST_data_1.csv')\n",
    "\n",
    "    predict_df = orginal_df[pd.isnull(orginal_df[target])]\n",
    "    true_x_for_prediction = predict_df.drop(columns=['ID',target],inplace= False)\n",
    "    ypred = xgbr.predict(true_x_for_prediction)\n",
    "\n",
    "    ypred = [ '%.2f' % elem for elem in ypred ]\n",
    "\n",
    "    predict_df[target] = ypred\n",
    "    predict_df[target] = predict_df[target].apply(lambda x: f\"{x}\"+p_v)\n",
    "\n",
    "    previous_df.set_index(['ID'], inplace=True)\n",
    "    previous_df.update(predict_df.set_index(['ID']))\n",
    "    previous_df.reset_index( inplace=True)\n",
    "    previous_df.to_csv(new_file_name,index = False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data set of the first layer of predictions was the data from ID, REST, and three related fields from the LRC section [WHY LRC? ](i.e. 17 columns in total, 1 ID column, 13 columns from the restaurant section, and 3 related columns from the LRC section). We marked this section of data as REST1 for the rest of the article.  After we spilt the REST1 into the training data set and the testing data set, we trained our XgbRegressor model with the training data set and tuned the parameters of the XgbRegressor using grid search and cross-validation method. Then we predicted the missing value from the 13 fields of the restaurant section in REST1. If the MAPE value for a particular field is > 0.35 (MAPE value is a metric that shows the modelâ€™s performance and the accuracy of the predicted data, the higher the MAPE is, meaning that the prediction is ), we dropped the prediction of that field and if the MAPE value for a particular field is < 0.35, we filling in the missing value of that particular field in the format of *(p1). The fields that are filling in missing values are:  REST: Staff size MOD\",  \"REST: No Wtr MOD\",\"REST: No Ktch Wkr MOD\",\"REST: No tables MOD\",\"REST: Monthly Expenses MOD\". The detailed MAPE value can be checked in the Perdiction.ipynb file.\n",
    "\n",
    "After the first layer of prediction, we conduct the second layer of prediction.The data set of the second layer of predictions was the data from REST1 and filled in missing data for columns that have MAPE < .35. We marked this section of data as REST2 for the rest of the article. Then we conducted the same procedure for REST1 to REST2. And we predicted the missing value for the 8 (13 - 5 fields that are predicted in layer 1) fields of the restaurant section in REST2. On the second layer of prediction, if the MAPE value for a particular field is > 0.5, we dropped the prediction of that field and if the MAPE value for a particular field is < 0.5, we fill in the missing value of that particular field in the format of *(p2). The fields that are filling in missing values are:  REST: Monthly Expenses MOD, REST: Total Partners MOD\",\"REST: No Act Part MOD\",\"REST:  No Pass Part MOD. The detailed MAPE value can be checked in the Perdiction.ipynb file. The detailed MAPE value can be checked in the Perdiction.ipynb file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First round prediction start for: REST: Staff size MOD\n",
      "Fitting 2 folds for each of 162 candidates, totalling 324 fits\n",
      "Best parameters: {'alpha': 0, 'lambda': 1, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 100}\n",
      "Best scores: -0.4712055346919227\n",
      "MAPE CV Score: 0.346 (0.154)\n",
      "-----Prediction END-------\n",
      "First round prediction start for: REST: No Wtr MOD\n",
      "Fitting 2 folds for each of 162 candidates, totalling 324 fits\n",
      "Best parameters: {'alpha': 0.5, 'lambda': 1, 'learning_rate': 0.05, 'max_depth': 3, 'n_estimators': 100}\n",
      "Best scores: -0.31172121821608\n",
      "MAPE CV Score: 0.222 (0.089)\n",
      "-----Prediction END-------\n",
      "First round prediction start for: REST: No Ktch Wkr MOD\n",
      "Fitting 2 folds for each of 162 candidates, totalling 324 fits\n",
      "Best parameters: {'alpha': 0, 'lambda': 0, 'learning_rate': 0.05, 'max_depth': 3, 'n_estimators': 600}\n",
      "Best scores: -0.233649934857513\n",
      "MAPE CV Score: 0.297 (0.193)\n",
      "-----Prediction END-------\n",
      "First round prediction start for: REST: No tables MOD\n",
      "Fitting 2 folds for each of 162 candidates, totalling 324 fits\n",
      "Best parameters: {'alpha': 0, 'lambda': 0.5, 'learning_rate': 0.01, 'max_depth': 1, 'n_estimators': 100}\n",
      "Best scores: -0.38692312550669117\n",
      "MAPE CV Score: 0.249 (0.035)\n",
      "-----Prediction END-------\n",
      "First round prediction start for: REST: Monthly Expenses MOD\n",
      "Fitting 2 folds for each of 162 candidates, totalling 324 fits\n",
      "Best parameters: {'alpha': 0, 'lambda': 0, 'learning_rate': 0.1, 'max_depth': 1, 'n_estimators': 1000}\n",
      "Best scores: -0.32268145233646583\n",
      "MAPE CV Score: 0.486 (0.303)\n",
      "-----Prediction END-------\n",
      "Second round prediction start for: REST: Monthly Expenses MOD\n",
      "Fitting 2 folds for each of 162 candidates, totalling 324 fits\n",
      "Best parameters: {'alpha': 1, 'lambda': 0, 'learning_rate': 0.1, 'max_depth': 1, 'n_estimators': 1000}\n",
      "Best scores: -0.023969353806687674\n",
      "MAPE CV Score: 0.028 (0.007)\n",
      "-----Prediction END-------\n",
      "Second round prediction start for: REST: Total Partners MOD\n",
      "Fitting 2 folds for each of 162 candidates, totalling 324 fits\n",
      "Best parameters: {'alpha': 1, 'lambda': 1, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 100}\n",
      "Best scores: -0.6089661950563907\n",
      "MAPE CV Score: 0.404 (0.133)\n",
      "-----Prediction END-------\n",
      "Second round prediction start for: REST: No Act Part MOD\n",
      "Fitting 2 folds for each of 162 candidates, totalling 324 fits\n",
      "Best parameters: {'alpha': 0.5, 'lambda': 1, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 100}\n",
      "Best scores: -0.4691957198374096\n",
      "MAPE CV Score: 0.423 (0.148)\n",
      "-----Prediction END-------\n",
      "Second round prediction start for: REST:  No Pass Part MOD\n",
      "Fitting 2 folds for each of 162 candidates, totalling 324 fits\n",
      "Best parameters: {'alpha': 1, 'lambda': 1, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 100}\n",
      "Best scores: -181.30516544916577\n",
      "MAPE CV Score: 105.879 (95.640)\n",
      "-----Prediction END-------\n"
     ]
    }
   ],
   "source": [
    "#doing first round of prediction\n",
    "Target = \"REST: Staff size MOD\" \n",
    "print(\"First round prediction start for:\",Target)\n",
    "x,y,xtrain, xtest, ytrain, ytest = SplitSet(Target,'./data/PredictionData/REST_data_1_Cleaned.csv')\n",
    "xgbr = XgbModel(xtrain,ytrain, x,y)\n",
    "Predict('./data/PredictionData/REST_data_1.csv',Target, xgbr,'./data/PredictionData/REST_data_1_predicted_v1_without_label.csv','')\n",
    "Predict('./data/PredictionData/REST_data_1.csv',Target, xgbr,'./data/PredictionData/REST_data_1_predicted_v1.csv','(p1)')\n",
    "print(\"-----Prediction END-------\")\n",
    "\n",
    "Targetlist = [ \"REST: No Wtr MOD\",\"REST: No Ktch Wkr MOD\",\"REST: No tables MOD\",\"REST: Monthly Expenses MOD\"]\n",
    "for Target in Targetlist:\n",
    "    print(\"First round prediction start for:\",Target)\n",
    "    x,y,xtrain, xtest, ytrain, ytest = SplitSet(Target,'./data/PredictionData/REST_data_1_Cleaned.csv')\n",
    "    xgbr = XgbModel(xtrain,ytrain, x,y)\n",
    "    Predict('./data/PredictionData/REST_data_1_predicted_v1_without_label.csv',Target, xgbr,'./data/PredictionData/REST_data_1_predicted_v1_without_label.csv','')\n",
    "    Predict('./data/PredictionData/REST_data_1_predicted_v1.csv',Target, xgbr,'./data/PredictionData/REST_data_1_predicted_v1.csv','(p1)')\n",
    "    print(\"-----Prediction END-------\")\n",
    "\n",
    "\n",
    "#doing second round of prediction\n",
    "Target = \"REST: Monthly Expenses MOD\"\n",
    "print(\"Second round prediction start for:\",Target)\n",
    "x,y,xtrain, xtest, ytrain, ytest = SplitSet(Target,'./data/PredictionData/REST_data_1_predicted_v1_without_label.csv')\n",
    "xgbr = XgbModel(xtrain,ytrain, x,y)\n",
    "Predict('./data/PredictionData/REST_data_1_predicted_v1_without_label.csv',Target, xgbr,'./data/PredictionData/REST_data_1_predicted_v2_without_label.csv','')\n",
    "Predict('./data/PredictionData/REST_data_1_predicted_v1.csv',Target, xgbr,'./data/PredictionData/REST_data_1_predicted_v2.csv','(p2)')\n",
    "print(\"-----Prediction END-------\")\n",
    "\n",
    "Targetlist = [\"REST: Total Partners MOD\",\"REST: No Act Part MOD\",\"REST:  No Pass Part MOD\"]\n",
    "for Target in Targetlist:\n",
    "    print(\"Second round prediction start for:\",Target)\n",
    "    x,y,xtrain, xtest, ytrain, ytest = SplitSet(Target,'./data/PredictionData/REST_data_1_predicted_v1_without_label.csv')\n",
    "    xgbr = XgbModel(xtrain,ytrain, x,y)\n",
    "    Predict('./data/PredictionData/REST_data_1_predicted_v2_without_label.csv',Target, xgbr,'./data/PredictionData/REST_data_1_predicted_v2_without_label.csv','')\n",
    "    Predict('./data/PredictionData/REST_data_1_predicted_v2.csv',Target, xgbr,'./data/PredictionData/REST_data_1_predicted_v2.csv','(p2)')\n",
    "    print(\"-----Prediction END-------\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the second layer of prediction, we conduct the third layer of prediction. The data set of the third layer of predictions was the data from REST2 and filled in missing data for columns that have MAPE < .5 We marked this section of data as REST3 for the rest of the article. Then we conducted the same procedure for REST1 to REST3. And we predicted the missing value for the 4 (13 - 5 fields that are predicted in layer 1 - 4 fields that are predicted in layer 2) fields of the restaurant section in REST3. On the third layer of prediction, we fill in all the missing values of these fields in the format of *(p3). ATTENTION: the MAPE for the fields in the third layer of prediction are > 0.5, meaning that the XgbRegressor is not doing a great job predicting data in the fields from the third layer, thus be careful when using the prediction from the third layer. The fields that are filling in missing values are:  REST: Monthly Sales MOD\" REST: Dividends MOD\",\"REST: Monthly rent MOD\",\"REST: Total Capital MOD\"\n",
    "The detailed MAPE value can be checked in the Perdiction.ipynb file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Third round prediction start for: REST: Monthly Sales MOD\n",
      "Fitting 2 folds for each of 162 candidates, totalling 324 fits\n",
      "Best parameters: {'alpha': 1, 'lambda': 1, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 100}\n",
      "Best scores: -0.5222423824244933\n",
      "MAPE CV Score: 0.576 (0.180)\n",
      "-----Prediction END-------\n",
      "Third round prediction start for: REST: Dividends MOD\n",
      "Fitting 2 folds for each of 162 candidates, totalling 324 fits\n",
      "Best parameters: {'alpha': 1, 'lambda': 0.5, 'learning_rate': 0.01, 'max_depth': 1, 'n_estimators': 100}\n",
      "Best scores: -0.6039485981551684\n",
      "MAPE CV Score: 0.901 (0.249)\n",
      "-----Prediction END-------\n",
      "Third round prediction start for: REST: Monthly rent MOD\n",
      "Fitting 2 folds for each of 162 candidates, totalling 324 fits\n",
      "Best parameters: {'alpha': 0, 'lambda': 1, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 100}\n",
      "Best scores: -0.5886857927641571\n",
      "MAPE CV Score: 0.721 (0.330)\n",
      "-----Prediction END-------\n",
      "Third round prediction start for: REST: Total Capital MOD\n",
      "Fitting 2 folds for each of 162 candidates, totalling 324 fits\n",
      "Best parameters: {'alpha': 0, 'lambda': 0.5, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 100}\n",
      "Best scores: -0.4105102455089613\n",
      "MAPE CV Score: 0.620 (0.285)\n",
      "-----Prediction END-------\n"
     ]
    }
   ],
   "source": [
    "#third round\n",
    "Target = \"REST: Monthly Sales MOD\"\n",
    "print(\"Third round prediction start for:\",Target)\n",
    "x,y,xtrain, xtest, ytrain, ytest = SplitSet(Target,'./data/PredictionData/REST_data_1_predicted_v2_without_label.csv')\n",
    "xgbr = XgbModel(xtrain,ytrain, x,y)\n",
    "Predict('./data/PredictionData/REST_data_1_predicted_v2.csv',Target, xgbr,'./data/PredictionData/REST_data_1_predicted_v3.csv','(p3)')\n",
    "\n",
    "print(\"-----Prediction END-------\")\n",
    "\n",
    "Targetlist = [\"REST: Dividends MOD\",\"REST: Monthly rent MOD\",\"REST: Total Capital MOD\"]\n",
    "for Target in Targetlist:\n",
    "    print(\"Third round prediction start for:\",Target)\n",
    "    x,y,xtrain, xtest, ytrain, ytest = SplitSet(Target,'./data/PredictionData/REST_data_1_predicted_v2_without_label.csv')\n",
    "    xgbr = XgbModel(xtrain,ytrain, x,y)\n",
    "    Predict('./data/PredictionData/REST_data_1_predicted_v3.csv',Target, xgbr,'./data/PredictionData/REST_data_1_predicted_v3.csv','(p3)')\n",
    "    print(\"-----Prediction END-------\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8 (default, Apr 13 2021, 12:59:45) \n[Clang 10.0.0 ]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "62246d9baa5270b215c46440235e1fc59d223b814ee5f271498789186de4e3ae"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
